{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf34787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather Data Analysis\n",
    "# This notebook analyzes a dataset of weather observations using pandas and visualization libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dca91d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 1. Notebook Setup\n",
    "# Import libraries and configure display/plotting options.\n",
    "import time\n",
    "start_time = time.time()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Display library versions\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"seaborn: {sns.__version__}\")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline  # Uncomment if running in a notebook\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Cell executed in {time.time() - start_time:.2f} seconds.\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Loading\n",
    "# Load the weather dataset into a pandas DataFrame.\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "file_path = 'Helios Weather Station20251230083828.xlsx'\n",
    "\n",
    "# Read all sheets at once into a dict of DataFrames\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "dfs = []\n",
    "for sheet_name, df in all_sheets.items():\n",
    "    if not df.empty and 'DateTime' in df.columns:\n",
    "        df = df.copy()\n",
    "        df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "        df = df.set_index('DateTime')\n",
    "        # Optionally, prefix columns with sheet name to avoid collisions\n",
    "        # df = df.add_prefix(f\"{sheet_name}_\")\n",
    "        dfs.append(df)\n",
    "\n",
    "if dfs:\n",
    "    # Join all dataframes on DateTime index, columns from each sheet are preserved\n",
    "    from functools import reduce\n",
    "    combined_df = reduce(lambda left, right: left.join(right, how='outer'), dfs)\n",
    "    combined_df = combined_df.sort_index()\n",
    "    # display(combined_df.head())\n",
    "    # display(combined_df.describe())\n",
    "    combined_df.info()\n",
    "    print(f\"DataFrame shape: {combined_df.shape}\")\n",
    "else:\n",
    "    print(\"No valid data found in any worksheet.\")\n",
    "\n",
    "df = combined_df\n",
    "df.info()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Loaded data in {end - start:.2f} seconds.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac207579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initial Data Inspection\n",
    "# Preview the data and basic statistics.\n",
    "\n",
    "display(df.head())\n",
    "# print(\"\\nColumn names:\", df.columns.tolist())\n",
    "# print(\"\\nData types:\")\n",
    "# print(df.dtypes)\n",
    "# print(\"\\nInfo:\")\n",
    "# df.info()\n",
    "# print(\"\\nSummary statistics:\")\n",
    "# display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Cleaning\n",
    "# Handle missing values, fix data types, and remove duplicates.\n",
    "\n",
    "print(f\"Missing values before cleaning:\\n{df.isnull().sum()}\")\n",
    "print(f\"Duplicates before cleaning: {df.duplicated().sum()}\")\n",
    "\n",
    "# Example cleaning steps (customize as needed)\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Missing values after cleaning:\\n{df.isnull().sum()}\")\n",
    "print(f\"Duplicates after cleaning: {df.duplicated().sum()}\")\n",
    "print(f\"DataFrame shape after cleaning: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Feature Engineering\n",
    "# Create new columns or transform existing ones.\n",
    "\n",
    "# Example: Convert temperature from Celsius to Fahrenheit if needed\n",
    "if 'temperature_C' in df.columns:\n",
    "    df['temperature_F'] = df['temperature_C'] * 9/5 + 32\n",
    "    print(\"Added 'temperature_F' column.\")\n",
    "\n",
    "# Example: Parse date column\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    print(\"Parsed 'date' column to datetime.\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Exploratory Data Analysis (EDA)\n",
    "# Visualize distributions, correlations, and trends.\n",
    "\n",
    "# Example: Histogram of temperature\n",
    "if 'temperature_C' in df.columns:\n",
    "    df['temperature_C'].hist(bins=30)\n",
    "    plt.title('Temperature Distribution (C)')\n",
    "    plt.xlabel('Temperature (C)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Example: Correlation heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a93338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Time Series Analysis\n",
    "# Aggregate or resample data by time.\n",
    "\n",
    "# Example: Daily average temperature\n",
    "if 'date' in df.columns and 'temperature_C' in df.columns:\n",
    "    daily_avg = df.set_index('date').resample('D')['temperature_C'].mean()\n",
    "    daily_avg.plot(figsize=(12,4))\n",
    "    plt.title('Daily Average Temperature (C)')\n",
    "    plt.ylabel('Temperature (C)')\n",
    "    plt.show()\n",
    "    print(daily_avg.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbede8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Outlier Detection\n",
    "# Identify and visualize outliers.\n",
    "\n",
    "# Example: Z-score method for temperature\n",
    "from scipy.stats import zscore\n",
    "if 'temperature_C' in df.columns:\n",
    "    df['temp_zscore'] = zscore(df['temperature_C'])\n",
    "    outliers = df[np.abs(df['temp_zscore']) > 3]\n",
    "    print(f\"Number of outliers: {outliers.shape[0]}\")\n",
    "    display(outliers[['date', 'temperature_C', 'temp_zscore']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46086ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Graphing and Visualization\n",
    "# Create final, publication-quality graphs.\n",
    "\n",
    "# Example: Boxplot of temperature by month\n",
    "if 'date' in df.columns and 'temperature_C' in df.columns:\n",
    "    df['month'] = df['date'].dt.month\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.boxplot(x='month', y='temperature_C', data=df)\n",
    "    plt.title('Monthly Temperature Distribution')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Temperature (C)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c7592",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 10. Conclusions and Next Steps\n",
    "# Summarize findings and suggest further analysis.\n",
    "\n",
    "# Summary of key insights\n",
    "from IPython.display import Markdown, display\n",
    "def print_insights():\n",
    "    display(Markdown('''\n",
    "- Data cleaned and prepared for analysis.\n",
    "- Key trends and outliers identified in temperature data.\n",
    "- Visualizations created for further reporting.\n",
    "- Next steps: deeper analysis, predictive modeling, or integration with other datasets.\n",
    "'''))\n",
    "\n",
    "print_insights()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
